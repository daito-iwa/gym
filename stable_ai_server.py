#!/usr/bin/env python3
"""
ğŸ† å®‰å®šç‰ˆä½“æ“AI - Stable Gymnastics AI Server with OpenAI
"""

from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any
import datetime
import os

app = FastAPI(title="Gymnastics AI API", version="1.5.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAIè¨­å®šï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚æ…é‡ã«ï¼‰
OPENAI_READY = False
try:
    import openai
    if os.getenv("OPENAI_API_KEY"):
        openai.api_key = os.getenv("OPENAI_API_KEY")
        OPENAI_READY = True
        print("âœ… OpenAI API configured successfully")
    else:
        print("âš ï¸ OpenAI API key not found")
except ImportError:
    print("âš ï¸ OpenAI library not available")

# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
class ChatMessage(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

# ã‚·ãƒ³ãƒ—ãƒ«ãªèªè¨¼
def get_current_user(authorization: str = Header(None)):
    return {
        "id": "device_user",
        "username": "device_user",
        "subscription_tier": "premium"
    }

# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/")
async def root():
    return {
        "message": "ğŸ† Gymnastics AI API Server", 
        "version": "1.5.0", 
        "status": "running",
        "ai_engine": "OpenAI GPT-4" if OPENAI_READY else "Basic Mode"
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy", 
        "timestamp": datetime.datetime.utcnow().isoformat(),
        "openai_ready": OPENAI_READY
    }

@app.post("/chat/message")
async def send_chat_message(chat_data: ChatMessage, current_user = Depends(get_current_user)):
    """ä½“æ“AIå°‚ç”¨ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    try:
        print(f"ğŸ”¥ Chat message received: {chat_data.message}")
        print(f"ğŸ”¥ OpenAI ready: {OPENAI_READY}")
        
        response_text = ""
        
        # OpenAI APIã‚’è©¦ã™ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        if OPENAI_READY:
            try:
                print("ğŸ¤– Calling OpenAI API...")
                
                system_prompt = """ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ä½“æ“AIã‚³ãƒ¼ãƒã§ã™ã€‚
                
å°‚é–€åˆ†é‡ï¼š
- ç”·å­ä½“æ“6ç¨®ç›®ãƒ»å¥³å­ä½“æ“4ç¨®ç›®ã®æŠ€è¡“æŒ‡å°
- FIGå…¬å¼ãƒ«ãƒ¼ãƒ«ã¨Då¾—ç‚¹è¨ˆç®—
- 820æŠ€ã®ä½“æ“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- ä½“æ“ä»¥å¤–ã®è³ªå•ã«ã‚‚è¦ªåˆ‡ã«å¯¾å¿œ

è¦ªåˆ‡ã§å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""
                
                # GPT-3.5ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": chat_data.message}
                    ],
                    max_tokens=800,
                    temperature=0.7
                )
                
                response_text = response.choices[0].message.content
                print(f"ğŸ¤– OpenAI response received: {len(response_text)} chars")
                
            except Exception as openai_error:
                print(f"âš ï¸ OpenAI API error: {openai_error}")
                response_text = None
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
        if not response_text:
            response_text = f"""**ğŸ¤– ä½“æ“å°‚é–€AI**

ã”è³ªå•ã€Œ{chat_data.message}ã€ã«ãŠç­”ãˆã—ã¾ã™ã€‚

ç§ã¯ä½“æ“ç«¶æŠ€ã®å°‚é–€AIã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ãªè³ªå•ã«ãŠç­”ãˆã§ãã¾ã™ï¼š

ğŸ… **ä½“æ“å°‚é–€åˆ†é‡ï¼š**
â€¢ æŠ€ã®é›£åº¦ã‚„è©³ç´°ï¼ˆ820æŠ€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
â€¢ Då¾—ç‚¹è¨ˆç®—ã¨Eå¾—ç‚¹è©•ä¾¡
â€¢ FIGå…¬å¼ãƒ«ãƒ¼ãƒ«è§£èª¬
â€¢ æ¼”æŠ€æ§‹æˆã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
â€¢ ç¨®ç›®åˆ¥ã®æŠ€è¡“æŒ‡å°

ğŸŒŸ **ä¸€èˆ¬çš„ãªè³ªå•ã«ã‚‚å¯¾å¿œï¼š**
â€¢ ã‚¹ãƒãƒ¼ãƒ„å…¨èˆ¬ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
â€¢ å¥åº·ãƒ»ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ç›¸è«‡
â€¢ ãã®ä»–ã®æ—¥å¸¸çš„ãªè³ªå•

ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ãŠèã‹ã›ãã ã•ã„ï¼"""
        
        print(f"ğŸ”¥ Response generated: {len(response_text)} chars")
        
        return {
            "response": response_text,
            "conversation_id": chat_data.conversation_id or "conv_1",
            "usage_count": 1,
            "remaining_count": 99,
            "ai_engine": "GPT-3.5" if OPENAI_READY and response_text else "Fallback"
        }
    
    except Exception as e:
        print(f"ğŸš¨ Chat error: {e}")
        import traceback
        print(f"ğŸš¨ Traceback: {traceback.format_exc()}")
        
        # ã‚¨ãƒ©ãƒ¼ã§ã‚‚å¿…ãšå¿œç­”ã‚’è¿”ã™
        return {
            "response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            "conversation_id": "error_conv",
            "usage_count": 0,
            "remaining_count": 99,
            "ai_engine": "Error Handler"
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)