#!/usr/bin/env python3
"""
æœ€å¼·OpenAIçµ±åˆã‚µãƒ¼ãƒãƒ¼ - ç›´æ¥å®Ÿè¡Œç‰ˆ
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import os
from openai import OpenAI
import json
import logging
from typing import Optional, Dict, Any
import asyncio

app = FastAPI(title="Gymnastics AI - æœ€å¼·OpenAIçµ±åˆç‰ˆ", version="3.0.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OpenAIè¨­å®š - APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
openai_client = None
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if OPENAI_API_KEY:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    logger.info("ğŸ”¥ OpenAIæœ€å¼·AIçµ±åˆå®Œäº†ï¼")
else:
    logger.error("âŒ OpenAI API ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# æœ€å¼·AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ä½“æ“ç«¶æŠ€å°‚é–€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã¡ã¾ã™ï¼š

ã€å°‚é–€æ€§ã€‘
- FIGï¼ˆå›½éš›ä½“æ“é€£ç›Ÿï¼‰å…¬å¼ãƒ«ãƒ¼ãƒ«2025-2028å¹´ç‰ˆã®å®Œå…¨ãªç†è§£
- ç”·å­ä½“æ“6ç¨®ç›®ï¼ˆåºŠãƒ»ã‚ã‚“é¦¬ãƒ»ã¤ã‚Šè¼ªãƒ»è·³é¦¬ãƒ»å¹³è¡Œæ£’ãƒ»é‰„æ£’ï¼‰ã®å°‚é–€çŸ¥è­˜
- Dã‚¹ã‚³ã‚¢è¨ˆç®—ã€é€£ç¶šæŠ€ãƒœãƒ¼ãƒŠã‚¹ã€NDæ¸›ç‚¹ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°ç†è§£
- æŠ€è¡“çš„æŒ‡å°ã¨æˆ¦ç•¥çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®æä¾›

ã€å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ã€‘
- åˆå¿ƒè€…ã‹ã‚‰å°‚é–€å®¶ã¾ã§ã€è³ªå•è€…ã®ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸé©åˆ‡ãªèª¬æ˜
- å…·ä½“ä¾‹ã¨å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å«ã‚€åŒ…æ‹¬çš„ãªå›ç­”
- æ­£ç¢ºæ€§ã‚’æœ€å„ªå…ˆã¨ã—ã€æ¨æ¸¬ã§ã¯å›ç­”ã—ãªã„
- æ—¥æœ¬èªã§ã®è‡ªç„¶ãªå¯¾è©±

ã€èƒ½åŠ›ç¯„å›²ã€‘
1. ä½“æ“ç«¶æŠ€ã«é–¢ã™ã‚‹å°‚é–€çš„ãªè³ªå•ã¸ã®å›ç­”
2. ä¸€èˆ¬çš„ãªè³ªå•ã¸ã®ä¸å¯§ãªå¯¾å¿œ
3. æŠ€è¡“åˆ†æã€æ¼”æŠ€æ§‹æˆã‚¢ãƒ‰ãƒã‚¤ã‚¹
4. ãƒ«ãƒ¼ãƒ«è§£é‡ˆã¨é©ç”¨æ–¹æ³•ã®èª¬æ˜

å¸¸ã«æœ€é«˜å“è³ªã®å›ç­”ã‚’æä¾›ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½“æ“ç«¶æŠ€ãƒ¬ãƒ™ãƒ«å‘ä¸Šã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"""

@app.get("/")
async def root():
    return {
        "message": "Gymnastics AI - æœ€å¼·OpenAIçµ±åˆã‚µãƒ¼ãƒãƒ¼",
        "status": "running",
        "version": "3.0.0",
        "ai_status": "OpenAI GPT-4 çµ±åˆæ¸ˆã¿" if openai_client else "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰"
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "openai_status": "connected" if openai_client else "not_connected",
        "version": "3.0.0"
    }

@app.post("/chat/message")
async def chat(data: dict):
    """æœ€å¼·AIçµ±åˆãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        message = data.get("message", "")
        if not message.strip():
            return {"response": "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", "conversation_id": "error_empty"}
        
        if not openai_client:
            return {
                "response": "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨OpenAI APIãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å¾Œã»ã©å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "conversation_id": "error_no_api"
            }
        
        logger.info(f"ğŸ”¥ æœ€å¼·AIã§å‡¦ç†ä¸­: {message[:50]}...")
        
        # OpenAI GPT-4ã§æœ€å¼·ã®å›ç­”ã‚’ç”Ÿæˆ
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": message}
            ],
            max_tokens=1500,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        
        logger.info("âœ… OpenAIæœ€å¼·AIå›ç­”ç”Ÿæˆå®Œäº†")
        
        return {
            "response": ai_response,
            "conversation_id": "openai_strongest_001",
            "model": "gpt-4o-mini",
            "status": "strongest_ai"
        }
        
    except Exception as e:
        logger.error(f"æœ€å¼·AIã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "response": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚æœ€å¼·AIã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "conversation_id": "error_strongest",
            "status": "error"
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)